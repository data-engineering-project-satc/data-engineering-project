{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a495f10-5886-465d-9e8c-bbcb419e4770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# --- CONFIGURAÇÃO DA CONEXÃO ---\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Validação para garantir que as variáveis foram carregadas\n",
    "if not all([db_user, db_password, db_host, db_port, db_name]):\n",
    "    raise ValueError(\"Uma ou mais variáveis de ambiente do banco de dados não foram definidas. Verifique o arquivo .env\")\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# --- DEFINIÇÃO DOS CAMINHOS ---\n",
    "gold_base_path = \"/mnt/datalake/gold/\"\n",
    "control_table_name = \"destiny._load_control\"\n",
    "\n",
    "# Tabelas da camada Gold para carregar no banco\n",
    "gold_tables_to_load = [\n",
    "    \"dim_companies\", \"dim_locations\", \"dim_skills\", \"dim_date\", \n",
    "    \"fact_jobs\", \"fact_job_skills\"\n",
    "]\n",
    "\n",
    "# --- FUNÇÕES DE CONTROLE ---\n",
    "\n",
    "def initialize_control_table():\n",
    "    \"\"\"Cria a tabela de controle se ela não existir.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=db_host, dbname=db_name, user=db_user, password=db_password, port=db_port)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Cria o esquema 'destiny' se não existir\n",
    "        cursor.execute(\"CREATE SCHEMA IF NOT EXISTS destiny;\")\n",
    "\n",
    "        # Cria a tabela de controle\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {control_table_name} (\n",
    "            table_name VARCHAR(255) PRIMARY KEY,\n",
    "            last_load_timestamp TIMESTAMP,\n",
    "            status VARCHAR(50)\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(f\"Tabela de controle '{control_table_name}' verificada/criada com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao inicializar a tabela de controle: {e}\")\n",
    "        raise e\n",
    "\n",
    "def check_if_loaded(table_name):\n",
    "    \"\"\"Verifica na tabela de controle se os dados já foram carregados com sucesso.\"\"\"\n",
    "    try:\n",
    "        # Tenta ler a contagem da tabela de controle\n",
    "        query = f\"(SELECT COUNT(*) FROM {control_table_name} WHERE table_name = '{table_name}' AND status = 'SUCCESS') as t\"\n",
    "        count_df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "        return count_df.first()[0] > 0\n",
    "    except AnalysisException as e:\n",
    "        # Se a tabela de controle não existe, retorna False (não foi carregado)\n",
    "        if \"relation\" in str(e) and \"does not exist\" in str(e):\n",
    "            return False\n",
    "        raise e\n",
    "\n",
    "def update_load_control(table_name, status):\n",
    "    \"\"\"Atualiza o status de carga na tabela de controle.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=db_host, dbname=db_name, user=db_user, password=db_password, port=db_port)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        upsert_query = f\"\"\"\n",
    "        INSERT INTO {control_table_name} (table_name, last_load_timestamp, status)\n",
    "        VALUES (%s, NOW(), %s)\n",
    "        ON CONFLICT (table_name) \n",
    "        DO UPDATE SET \n",
    "            last_load_timestamp = NOW(),\n",
    "            status = %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(upsert_query, (table_name, status, status))\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(f\"Controle de carga atualizado para '{table_name}' com status '{status}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao atualizar o controle de carga: {e}\")\n",
    "\n",
    "\n",
    "# --- PROCESSO DE CARGA ---\n",
    "\n",
    "print(\"Iniciando carga da camada Gold para o banco de dados...\")\n",
    "\n",
    "# 1. Garante que a tabela de controle exista\n",
    "initialize_control_table()\n",
    "\n",
    "# 2. Loop para carregar cada tabela\n",
    "for table_name in gold_tables_to_load:\n",
    "    # Verifica se já foi carregada\n",
    "    if check_if_loaded(table_name):\n",
    "        print(f\"Tabela '{table_name}' já foi carregada com sucesso. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"Iniciando carga da tabela '{table_name}'...\")\n",
    "        \n",
    "        # Carrega os dados da camada Gold\n",
    "        df_gold = spark.read.format(\"delta\").load(f\"{gold_base_path}{table_name}\")\n",
    "        \n",
    "        # Define o nome da tabela de destino no esquema 'destiny'\n",
    "        destiny_table_name = f\"destiny.{table_name}\"\n",
    "        \n",
    "        df_gold.write.jdbc(\n",
    "            url=jdbc_url,\n",
    "            table=destiny_table_name,\n",
    "            mode=\"overwrite\", \n",
    "            properties=connection_properties\n",
    "        )\n",
    "        \n",
    "        print(f\"Tabela '{table_name}' carregada com sucesso no banco de dados.\")\n",
    "        \n",
    "        # Atualiza a tabela de controle com o status de sucesso\n",
    "        update_load_control(table_name, \"SUCCESS\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao carregar a tabela '{table_name}': {e}\")\n",
    "        # Atualiza a tabela de controle com o status de falha\n",
    "        update_load_control(table_name, \"FAILED\")\n",
    "        break\n",
    "\n",
    "print(\"Processo de carga para o banco de dados finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_load_to_db.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
