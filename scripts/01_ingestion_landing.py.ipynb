{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "434fd8e0-cdb7-49c6-98f9-6f49e6c2e4b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# --- CONFIGURAÇÃO DA CONEXÃO COM POSTGRESQL (SUPABASE) ---\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Validação para garantir que as variáveis foram carregadas\n",
    "if not all([db_user, db_password, db_host, db_port, db_name]):\n",
    "    raise ValueError(\"Uma ou mais variáveis de ambiente do banco de dados não foram definidas. Verifique o arquivo .env\")\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# --- PROCESSO DE INGESTÃO ---\n",
    "\n",
    "# Lista de tabelas para ingestão\n",
    "tables = [\n",
    "    \"companies\", \"company_reviews\", \"employment_types\", \"industries\",\n",
    "    \"job_benefits\", \"job_skills\", \"jobs\", \"locations\", \"salary_ranges\", \"skills\"\n",
    "]\n",
    "\n",
    "# Loop para ler cada tabela e salvar na camada Landing como CSV\n",
    "for table_name in tables:\n",
    "    print(f\"Iniciando ingestão da tabela: {table_name}\")\n",
    "\n",
    "    try:\n",
    "        # Leitura da tabela do banco de dados\n",
    "        df = spark.read.jdbc(url=jdbc_url, table=f\"public.{table_name}\", properties=connection_properties)\n",
    "\n",
    "        # Define o caminho de destino na camada Landing\n",
    "        landing_path = f\"/mnt/datalake/landing/{table_name}\"\n",
    "\n",
    "        # Salva os dados como CSV\n",
    "        df.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(landing_path)\n",
    "\n",
    "        print(f\"Tabela {table_name} salva em {landing_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ingerir a tabela {table_name}: {e}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingestion_landing.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
